{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import glob\n",
    "import os\n",
    "import sounddevice as sd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from scipy.io.wavfile import write\n",
    "from scipy.io.wavfile import read\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 44100\n",
    "max_len=300\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "Vocal channel (01 = speech, 02 = song).\n",
    "Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the ‘neutral’ emotion.\n",
    "Statement (01 = “Kids are talking by the door”, 02 = “Dogs are sitting by the door”).\n",
    "Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "\n",
    "C:\\Users\\tmacovei001\\Desktop\\ravdess-emotional-speech-audio\\All\\03-01-01-01-01-01-01.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-fcfc6b71f88c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mperson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mperson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0my2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperson\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mfile_temp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfs_temp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mmfcc_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_temp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_len\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmfcc_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample_poly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sr\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mgcd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_sr\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mgcd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\resampy\\core.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mresample_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "y =[]\n",
    "\n",
    "y2=[]\n",
    "\n",
    "for file in glob.glob(\"C:\\\\Users\\\\tmacovei001\\\\Desktop\\\\Speaker Recognition\\\\Datasets\\\\Ravdess\\\\All\\\\*\"):\n",
    "    basename=os.path.basename(file)\n",
    "    emotion=basename.split(\"-\")[2]\n",
    "    person=basename.split(\"-\")[6]\n",
    "    person=person.split(\".\")[0]\n",
    "    y2.append(int(person)-1)\n",
    "    file_temp,fs_temp=librosa.load(file, sr=fs)\n",
    "    mfcc_features=librosa.feature.mfcc(file_temp,sr=fs, S=None, n_mfcc=20)\n",
    "    if (max_len > mfcc_features.shape[1]):\n",
    "        pad_width = max_len - mfcc_features.shape[1]\n",
    "        mfcc_features = np.pad(mfcc_features, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc_features = mfcc_features[:, :max_len]\n",
    "    x.append(mfcc_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)\n",
    "y2=np.array(y2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 13, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that mfcc operation returns (n_mfcc, time). \n",
    "#You have to do an axis permutation to get it to (time, n_mfcc) format. \n",
    "#So that the convolution happens on the time dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Normalize!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_classes=max(y2)+1\n",
    "nb_filter1=16\n",
    "nb_filter2=8\n",
    "nb_filter3=4\n",
    "no_channels=1\n",
    "filter_length=3\n",
    "filter_length2=2\n",
    "length=39\n",
    "no_mfcc=20\n",
    "x_reshape=(x.shape[0],no_mfcc,x.shape[2],no_channels)\n",
    "input_shape=(no_mfcc,x.shape[2],no_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as sk\n",
    "x = x.reshape(x_reshape)\n",
    "\n",
    "x_train, x_test, y2_train, y2_test = sk.train_test_split(x,y2,test_size=0.3)\n",
    "y2_train = tf.keras.utils.to_categorical(y2_train,num_classes=no_classes)\n",
    "y2_test = tf.keras.utils.to_categorical(y2_test,num_classes=no_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_11/MaxPool' (op: 'MaxPool') with input shapes: [?,1,73,64].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1618\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1619\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1620\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_11/MaxPool' (op: 'MaxPool') with input shapes: [?,1,73,64].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-b6f9a7f8f8cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    201\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    771\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    772\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         data_format=conv_utils.convert_data_format(self.data_format, 4))\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(value, ksize, strides, padding, data_format, name, input)\u001b[0m\n\u001b[0;32m   3873\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3874\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3875\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   3876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m   5197\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m   5198\u001b[0m         \u001b[1;34m\"MaxPool\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5199\u001b[1;33m                    data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m   5200\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5201\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    740\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0;32m    741\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[0;32m    743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[1;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         compute_device)\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3320\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3321\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3322\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3323\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3324\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1784\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1785\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1786\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1787\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1788\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1620\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1621\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1622\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1624\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_11/MaxPool' (op: 'MaxPool') with input shapes: [?,1,73,64]."
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(48, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(no_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 49, 299, 32)       160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 149, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 23, 148, 48)       6192      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 74, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 73, 64)        12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 36, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 11520)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 24)                276504    \n",
      "=================================================================\n",
      "Total params: 295,208\n",
      "Trainable params: 295,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1008 samples, validate on 432 samples\n",
      "Epoch 1/20\n",
      "1008/1008 - 6s - loss: 9.2396 - accuracy: 0.0903 - val_loss: 2.7099 - val_accuracy: 0.2245\n",
      "Epoch 2/20\n",
      "1008/1008 - 5s - loss: 1.9510 - accuracy: 0.4107 - val_loss: 1.8570 - val_accuracy: 0.4468\n",
      "Epoch 3/20\n",
      "1008/1008 - 5s - loss: 0.8977 - accuracy: 0.7371 - val_loss: 1.3139 - val_accuracy: 0.6088\n",
      "Epoch 4/20\n",
      "1008/1008 - 5s - loss: 0.2966 - accuracy: 0.9266 - val_loss: 1.3845 - val_accuracy: 0.6111\n",
      "Epoch 5/20\n",
      "1008/1008 - 5s - loss: 0.1217 - accuracy: 0.9712 - val_loss: 1.5737 - val_accuracy: 0.6065\n",
      "Epoch 6/20\n",
      "1008/1008 - 5s - loss: 0.0540 - accuracy: 0.9931 - val_loss: 1.3712 - val_accuracy: 0.6644\n",
      "Epoch 7/20\n",
      "1008/1008 - 5s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.3478 - val_accuracy: 0.6782\n",
      "Epoch 8/20\n",
      "1008/1008 - 5s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.3312 - val_accuracy: 0.6759\n",
      "Epoch 9/20\n",
      "1008/1008 - 5s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3375 - val_accuracy: 0.6875\n",
      "Epoch 10/20\n",
      "1008/1008 - 6s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3623 - val_accuracy: 0.6852\n",
      "Epoch 11/20\n",
      "1008/1008 - 6s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3743 - val_accuracy: 0.6829\n",
      "Epoch 12/20\n",
      "1008/1008 - 6s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3955 - val_accuracy: 0.6829\n",
      "Epoch 13/20\n",
      "1008/1008 - 6s - loss: 9.7945e-04 - accuracy: 1.0000 - val_loss: 1.4093 - val_accuracy: 0.6829\n",
      "Epoch 14/20\n",
      "1008/1008 - 6s - loss: 8.4551e-04 - accuracy: 1.0000 - val_loss: 1.4276 - val_accuracy: 0.6829\n",
      "Epoch 15/20\n",
      "1008/1008 - 6s - loss: 7.4354e-04 - accuracy: 1.0000 - val_loss: 1.4308 - val_accuracy: 0.6806\n",
      "Epoch 16/20\n",
      "1008/1008 - 6s - loss: 6.5559e-04 - accuracy: 1.0000 - val_loss: 1.4490 - val_accuracy: 0.6782\n",
      "Epoch 17/20\n",
      "1008/1008 - 6s - loss: 5.7757e-04 - accuracy: 1.0000 - val_loss: 1.4557 - val_accuracy: 0.6806\n",
      "Epoch 18/20\n",
      "1008/1008 - 6s - loss: 5.1506e-04 - accuracy: 1.0000 - val_loss: 1.4663 - val_accuracy: 0.6829\n",
      "Epoch 19/20\n",
      "1008/1008 - 6s - loss: 4.6842e-04 - accuracy: 1.0000 - val_loss: 1.4781 - val_accuracy: 0.6806\n",
      "Epoch 20/20\n",
      "1008/1008 - 6s - loss: 4.2103e-04 - accuracy: 1.0000 - val_loss: 1.4865 - val_accuracy: 0.6806\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y2_train, epochs=20,verbose=2, validation_data=(x_test,y2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 - 1s - loss: 1.4865 - accuracy: 0.6806\n",
      "\n",
      "Test accuracy: 0.6805556\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,  y2_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x274ad21cef0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
